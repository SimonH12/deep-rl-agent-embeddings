{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:18.672062Z",
     "start_time": "2025-08-10T14:10:16.098001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "import torch\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "dir0 = os.path.dirname(dir1)  # One level above dir1\n",
    "\n",
    "\n",
    "if dir1 not in sys.path: sys.path.append(dir0)\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "dir0 = os.path.dirname(dir1)  # One level above dir1\n",
    "\n",
    "\n",
    "if dir1 not in sys.path: sys.path.append(dir0)\n",
    "\n",
    "from src.config import PPOConfig, EmbeddingStrategy\n",
    "from src.experiments import ExperimentSuite\n",
    "from src.utils import ExperimentUtils\n",
    "\n",
    "\n",
    "def plot_rewards_of_strategy_in_env(strategy, file_name, max_agents=5, agents=[5,10,15,20,25,30,35,40]):\n",
    "    url = \"saved_experiments\" + \"/\" + file_name\n",
    "    base_config_balance_5_agents = PPOConfig(\n",
    "        scenario_name='balance', max_agents=max_agents, strategy=strategy, use_strategy_defaults=True, n_iters=80\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_agents\": agents\n",
    "    }\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    suite = ExperimentSuite(base_config=base_config_balance_5_agents, param_grid=param_grid, name=\"test_all\", device=my_device)\n",
    "    suite.run_all_confidence(k=1, profile_once=True)\n",
    "\n",
    "    suite_utils = ExperimentUtils(path=url, experiment_suite=suite)\n",
    "    suite_utils.save_df_to_file()\n",
    "    # suite_utils.plot_experiment_suite_df()\n",
    "    # print(suite_utils.create_table_with_confidence())"
   ],
   "id": "87333f3ff841d342",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:18.726631Z",
     "start_time": "2025-08-10T14:10:18.725149Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_rewards_of_strategy_in_env(EmbeddingStrategy.CONCAT, file_name='1_scale_concat.csv')",
   "id": "c80d6db45969c39c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:18.735189Z",
     "start_time": "2025-08-10T14:10:18.733568Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_rewards_of_strategy_in_env(EmbeddingStrategy.MLP, file_name='1_scale_mlps.csv')",
   "id": "80b2152bc0f6bd63",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:18.746904Z",
     "start_time": "2025-08-10T14:10:18.745556Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_rewards_of_strategy_in_env(EmbeddingStrategy.MLP_LOCAL, file_name='1_scale_mlp_local.csv')",
   "id": "a6df35053dbe672c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:18.763204Z",
     "start_time": "2025-08-10T14:10:18.761681Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_rewards_of_strategy_in_env(EmbeddingStrategy.MLP_GLOBAL, file_name='1_scale_mlp_global.csv')",
   "id": "7959f0b83e032e34",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:18.773832Z",
     "start_time": "2025-08-10T14:10:18.772250Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_rewards_of_strategy_in_env(EmbeddingStrategy.GRAPH_SAGE, file_name='1_scale_gsage.csv')",
   "id": "7e04cb3b327c35bc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T14:10:18.784719Z",
     "start_time": "2025-08-10T14:10:18.783119Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_rewards_of_strategy_in_env(EmbeddingStrategy.GRAPH_GAT, file_name='1_scale_gat.csv')",
   "id": "6489384eae11e895",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T17:35:51.353330Z",
     "start_time": "2025-08-10T14:10:18.794254Z"
    }
   },
   "cell_type": "code",
   "source": "plot_rewards_of_strategy_in_env(EmbeddingStrategy.GRAPH_GAT_v2, file_name='1_scale_gatv2.csv')",
   "id": "e6909951eb5c22a9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 16:10:18,824 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:10:19,041 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0:   0%|          | 0/80 [00:00<?, ?it/s]/opt/miniconda3/envs/ma_rl/lib/python3.9/site-packages/torch_geometric/utils/_scatter.py:102: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::scatter_reduce_.two. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/BatchedFallback.cpp:84.)\n",
      "  return src.new_zeros(size).scatter_reduce_(\n",
      "/opt/miniconda3/envs/ma_rl/lib/python3.9/site-packages/torch_geometric/utils/_scatter.py:75: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::scatter_add_. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/BatchedFallback.cpp:84.)\n",
      "  return src.new_zeros(size).scatter_add_(dim, index, src)\n",
      "episode_reward_mean = 88.51748657226562: 100%|██████████| 80/80 [02:10<00:00,  1.64s/it]  \n",
      "2025-08-10 16:12:29,993 [torchrl][INFO] Training time: 73.27 seconds\n",
      "2025-08-10 16:12:29,999 [torchrl][INFO] macs: 11.62 MMac  Params: 10.37 k\n",
      "2025-08-10 16:12:30,812 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:12:30,847 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0:   0%|          | 0/10 [00:00<?, ?it/s][W810 16:12:31.238541000 CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "episode_reward_mean = -0.8924632668495178: 100%|██████████| 10/10 [00:33<00:00,  3.36s/it]\n",
      "2025-08-10 16:13:04,416 [torchrl][INFO] Training time: 26.27 seconds\n",
      "2025-08-10 16:13:17,726 [torchrl][INFO] macs: 11.62 MMac  Params: 10.37 k\n",
      "2025-08-10 16:13:18,465 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:13:18,512 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 99.72785949707031: 100%|██████████| 80/80 [06:00<00:00,  4.50s/it]  \n",
      "2025-08-10 16:19:18,518 [torchrl][INFO] Training time: 248.65 seconds\n",
      "2025-08-10 16:19:18,534 [torchrl][INFO] macs: 23.24 MMac  Params: 10.37 k\n",
      "2025-08-10 16:19:20,054 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:19:20,119 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0.42690545320510864: 100%|██████████| 10/10 [01:01<00:00,  6.19s/it]\n",
      "2025-08-10 16:20:22,043 [torchrl][INFO] Training time: 49.21 seconds\n",
      "2025-08-10 16:20:35,745 [torchrl][INFO] macs: 23.24 MMac  Params: 10.37 k\n",
      "2025-08-10 16:20:37,108 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:20:37,179 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 107.13313293457031: 100%|██████████| 80/80 [09:59<00:00,  7.50s/it]\n",
      "2025-08-10 16:30:36,785 [torchrl][INFO] Training time: 447.02 seconds\n",
      "2025-08-10 16:30:36,803 [torchrl][INFO] macs: 34.85 MMac  Params: 10.37 k\n",
      "2025-08-10 16:30:38,934 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:30:39,023 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 24.793249130249023: 100%|██████████| 10/10 [01:32<00:00,  9.20s/it]\n",
      "2025-08-10 16:32:11,066 [torchrl][INFO] Training time: 75.48 seconds\n",
      "2025-08-10 16:32:24,419 [torchrl][INFO] macs: 34.85 MMac  Params: 10.37 k\n",
      "2025-08-10 16:32:25,908 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:32:25,999 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 55.220062255859375: 100%|██████████| 80/80 [15:18<00:00, 11.48s/it]\n",
      "2025-08-10 16:47:44,134 [torchrl][INFO] Training time: 720.14 seconds\n",
      "2025-08-10 16:47:44,163 [torchrl][INFO] macs: 46.47 MMac  Params: 10.37 k\n",
      "2025-08-10 16:47:46,812 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:47:47,000 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 8.834315299987793: 100%|██████████| 10/10 [02:13<00:00, 13.37s/it] \n",
      "2025-08-10 16:50:00,728 [torchrl][INFO] Training time: 111.93 seconds\n",
      "2025-08-10 16:50:13,653 [torchrl][INFO] macs: 46.47 MMac  Params: 10.37 k\n",
      "2025-08-10 16:50:15,531 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 16:50:15,646 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 59.36384963989258: 100%|██████████| 80/80 [21:38<00:00, 16.23s/it] \n",
      "2025-08-10 17:11:53,783 [torchrl][INFO] Training time: 1063.52 seconds\n",
      "2025-08-10 17:11:53,826 [torchrl][INFO] macs: 58.09 MMac  Params: 10.37 k\n",
      "2025-08-10 17:11:56,972 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 17:11:57,099 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -1.9552364349365234:  20%|██        | 2/10 [00:35<02:22, 17.77s/it][W810 17:12:47.412006000 CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "episode_reward_mean = 13.728752136230469: 100%|██████████| 10/10 [03:03<00:00, 18.34s/it]\n",
      "2025-08-10 17:15:00,518 [torchrl][INFO] Training time: 154.53 seconds\n",
      "2025-08-10 17:15:10,513 [torchrl][INFO] macs: 58.09 MMac  Params: 10.37 k\n",
      "2025-08-10 17:15:13,011 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 17:15:13,138 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 23.251054763793945: 100%|██████████| 80/80 [29:03<00:00, 21.80s/it]  \n",
      "2025-08-10 17:44:16,892 [torchrl][INFO] Training time: 1461.21 seconds\n",
      "2025-08-10 17:44:16,955 [torchrl][INFO] macs: 69.71 MMac  Params: 10.37 k\n",
      "2025-08-10 17:44:20,837 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 17:44:20,991 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -1.7065434455871582:  30%|███       | 3/10 [01:11<02:48, 24.00s/it][W810 17:45:46.057303000 CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "episode_reward_mean = 3.858504295349121: 100%|██████████| 10/10 [04:03<00:00, 24.35s/it] \n",
      "2025-08-10 17:48:24,477 [torchrl][INFO] Training time: 210.67 seconds\n",
      "2025-08-10 17:48:34,742 [torchrl][INFO] macs: 69.71 MMac  Params: 10.37 k\n",
      "2025-08-10 17:48:37,737 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 17:48:37,895 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 22.8216552734375: 100%|██████████| 80/80 [40:46<00:00, 30.58s/it]   \n",
      "2025-08-10 18:29:24,632 [torchrl][INFO] Training time: 2084.26 seconds\n",
      "2025-08-10 18:29:24,704 [torchrl][INFO] macs: 81.33 MMac  Params: 10.37 k\n",
      "2025-08-10 18:29:29,677 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 18:29:29,849 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -3.0755112171173096:  30%|███       | 3/10 [01:34<03:40, 31.47s/it][W810 18:31:17.178755000 CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "episode_reward_mean = -6.473235130310059: 100%|██████████| 10/10 [05:26<00:00, 32.62s/it]\n",
      "2025-08-10 18:34:56,059 [torchrl][INFO] Training time: 284.22 seconds\n",
      "2025-08-10 18:35:07,658 [torchrl][INFO] macs: 81.33 MMac  Params: 10.37 k\n",
      "2025-08-10 18:35:11,799 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 18:35:11,983 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 9.871719360351562: 100%|██████████| 80/80 [53:13<00:00, 39.91s/it]  \n",
      "2025-08-10 19:28:25,079 [torchrl][INFO] Training time: 2747.00 seconds\n",
      "2025-08-10 19:28:25,178 [torchrl][INFO] macs: 92.94 MMac  Params: 10.37 k\n",
      "2025-08-10 19:28:31,501 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 19:28:31,710 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -1.95443856716156:  10%|█         | 1/10 [00:40<06:02, 40.28s/it][W810 19:29:37.826973000 CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "episode_reward_mean = -1.2435636520385742: 100%|██████████| 10/10 [07:02<00:00, 42.26s/it]\n",
      "2025-08-10 19:35:34,352 [torchrl][INFO] Training time: 370.11 seconds\n",
      "2025-08-10 19:35:47,227 [torchrl][INFO] macs: 92.94 MMac  Params: 10.37 k\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T19:03:19.019361Z",
     "start_time": "2025-08-10T17:35:51.789926Z"
    }
   },
   "cell_type": "code",
   "source": "plot_rewards_of_strategy_in_env(EmbeddingStrategy.SET_TRANSFORMER_INV, file_name='1_scale_st.csv')",
   "id": "c223d80cbe00cc81",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 19:35:51,824 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 19:35:51,861 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 106.10822296142578: 100%|██████████| 80/80 [03:09<00:00,  2.36s/it]\n",
      "2025-08-10 19:39:01,036 [torchrl][INFO] Training time: 117.70 seconds\n",
      "2025-08-10 19:39:01,046 [torchrl][INFO] macs: 49.17 MMac  Params: 35.47 k\n",
      "2025-08-10 19:39:02,024 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 19:39:02,088 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 98.55065155029297: 100%|██████████| 80/80 [06:17<00:00,  4.71s/it]  \n",
      "2025-08-10 19:45:19,205 [torchrl][INFO] Training time: 279.35 seconds\n",
      "2025-08-10 19:45:19,221 [torchrl][INFO] macs: 92.66 MMac  Params: 35.47 k\n",
      "2025-08-10 19:45:20,605 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 19:45:20,689 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 81.26346588134766: 100%|██████████| 80/80 [08:10<00:00,  6.14s/it] \n",
      "2025-08-10 19:53:31,543 [torchrl][INFO] Training time: 353.84 seconds\n",
      "2025-08-10 19:53:31,563 [torchrl][INFO] macs: 136.15 MMac  Params: 35.47 k\n",
      "2025-08-10 19:53:33,449 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 19:53:33,549 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 106.36173248291016: 100%|██████████| 80/80 [09:51<00:00,  7.39s/it]\n",
      "2025-08-10 20:03:24,734 [torchrl][INFO] Training time: 409.96 seconds\n",
      "2025-08-10 20:03:24,754 [torchrl][INFO] macs: 179.64 MMac  Params: 35.47 k\n",
      "2025-08-10 20:03:27,283 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 20:03:27,405 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 76.11007690429688: 100%|██████████| 80/80 [11:45<00:00,  8.82s/it]  \n",
      "2025-08-10 20:15:13,186 [torchrl][INFO] Training time: 484.88 seconds\n",
      "2025-08-10 20:15:13,208 [torchrl][INFO] macs: 223.13 MMac  Params: 35.47 k\n",
      "2025-08-10 20:15:16,234 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 20:15:16,379 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 47.48234939575195: 100%|██████████| 80/80 [13:28<00:00, 10.11s/it]  \n",
      "2025-08-10 20:28:45,013 [torchrl][INFO] Training time: 541.01 seconds\n",
      "2025-08-10 20:28:45,038 [torchrl][INFO] macs: 266.62 MMac  Params: 35.47 k\n",
      "2025-08-10 20:28:48,821 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 20:28:48,988 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 19.675247192382812: 100%|██████████| 80/80 [16:01<00:00, 12.02s/it]  \n",
      "2025-08-10 20:44:50,806 [torchrl][INFO] Training time: 607.51 seconds\n",
      "2025-08-10 20:44:50,833 [torchrl][INFO] macs: 310.11 MMac  Params: 35.47 k\n",
      "2025-08-10 20:44:56,286 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 20:44:56,477 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -5.452723026275635: 100%|██████████| 80/80 [18:17<00:00, 13.71s/it] \n",
      "2025-08-10 21:03:13,532 [torchrl][INFO] Training time: 685.56 seconds\n",
      "2025-08-10 21:03:13,558 [torchrl][INFO] macs: 353.6 MMac  Params: 35.47 k\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T20:21:56.489841Z",
     "start_time": "2025-08-10T19:03:19.044559Z"
    }
   },
   "cell_type": "code",
   "source": "plot_rewards_of_strategy_in_env(EmbeddingStrategy.SAB_TRANSFORMER, file_name='1_scale_sab.csv')",
   "id": "ce28bcf8d441050f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 21:03:19,088 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 21:03:19,138 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 105.08464050292969: 100%|██████████| 80/80 [03:50<00:00,  2.88s/it]\n",
      "2025-08-10 21:07:09,926 [torchrl][INFO] Training time: 159.21 seconds\n",
      "2025-08-10 21:07:09,932 [torchrl][INFO] macs: 51.07 MMac  Params: 24.13 k\n",
      "2025-08-10 21:07:10,940 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 21:07:11,003 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 111.2874984741211: 100%|██████████| 80/80 [05:38<00:00,  4.24s/it] \n",
      "2025-08-10 21:12:49,944 [torchrl][INFO] Training time: 238.48 seconds\n",
      "2025-08-10 21:12:49,960 [torchrl][INFO] macs: 107.27 MMac  Params: 24.13 k\n",
      "2025-08-10 21:12:51,356 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 21:12:51,437 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 72.73319244384766: 100%|██████████| 80/80 [08:36<00:00,  6.46s/it] \n",
      "2025-08-10 21:21:28,150 [torchrl][INFO] Training time: 377.38 seconds\n",
      "2025-08-10 21:21:28,167 [torchrl][INFO] macs: 168.58 MMac  Params: 24.13 k\n",
      "2025-08-10 21:21:30,091 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 21:21:30,191 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 84.0407943725586: 100%|██████████| 80/80 [08:26<00:00,  6.33s/it]  \n",
      "2025-08-10 21:29:56,657 [torchrl][INFO] Training time: 319.71 seconds\n",
      "2025-08-10 21:29:56,670 [torchrl][INFO] macs: 235.02 MMac  Params: 24.13 k\n",
      "2025-08-10 21:29:59,329 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 21:29:59,453 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 95.67181396484375: 100%|██████████| 80/80 [10:23<00:00,  7.79s/it] \n",
      "2025-08-10 21:40:22,646 [torchrl][INFO] Training time: 387.28 seconds\n",
      "2025-08-10 21:40:22,661 [torchrl][INFO] macs: 306.57 MMac  Params: 24.13 k\n",
      "2025-08-10 21:40:25,944 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 21:40:26,090 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 46.6343994140625: 100%|██████████| 80/80 [11:52<00:00,  8.90s/it]  \n",
      "2025-08-10 21:52:18,191 [torchrl][INFO] Training time: 418.50 seconds\n",
      "2025-08-10 21:52:18,210 [torchrl][INFO] macs: 383.24 MMac  Params: 24.13 k\n",
      "2025-08-10 21:52:22,230 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 21:52:22,400 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 12.948363304138184: 100%|██████████| 80/80 [13:45<00:00, 10.32s/it]  \n",
      "2025-08-10 22:06:07,642 [torchrl][INFO] Training time: 464.72 seconds\n",
      "2025-08-10 22:06:07,658 [torchrl][INFO] macs: 465.04 MMac  Params: 24.13 k\n",
      "2025-08-10 22:06:12,853 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 22:06:13,047 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 10.999288558959961: 100%|██████████| 80/80 [15:37<00:00, 11.72s/it] \n",
      "2025-08-10 22:21:50,425 [torchrl][INFO] Training time: 494.86 seconds\n",
      "2025-08-10 22:21:50,447 [torchrl][INFO] macs: 551.95 MMac  Params: 24.13 k\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:40:35.405306Z",
     "start_time": "2025-08-10T20:21:56.516872Z"
    }
   },
   "cell_type": "code",
   "source": "plot_rewards_of_strategy_in_env(EmbeddingStrategy.ISAB_TRANSFORMER, file_name='1_scale_isab.csv')",
   "id": "f9ad238032b0fab5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:21:56,562 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 22:21:56,613 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 103.60740661621094: 100%|██████████| 80/80 [03:04<00:00,  2.30s/it]   \n",
      "2025-08-10 22:25:00,726 [torchrl][INFO] Training time: 111.36 seconds\n",
      "2025-08-10 22:25:00,735 [torchrl][INFO] macs: 62.9 MMac  Params: 57.54 k\n",
      "2025-08-10 22:25:01,767 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 22:25:01,829 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 93.68248748779297: 100%|██████████| 80/80 [06:15<00:00,  4.69s/it] \n",
      "2025-08-10 22:31:17,171 [torchrl][INFO] Training time: 275.14 seconds\n",
      "2025-08-10 22:31:17,184 [torchrl][INFO] macs: 112.44 MMac  Params: 57.54 k\n",
      "2025-08-10 22:31:18,588 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 22:31:18,671 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 102.21321105957031: 100%|██████████| 80/80 [07:36<00:00,  5.71s/it]\n",
      "2025-08-10 22:38:55,626 [torchrl][INFO] Training time: 319.01 seconds\n",
      "2025-08-10 22:38:55,640 [torchrl][INFO] macs: 161.98 MMac  Params: 57.54 k\n",
      "2025-08-10 22:38:57,540 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 22:38:57,642 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 92.19508361816406: 100%|██████████| 80/80 [09:01<00:00,  6.76s/it] \n",
      "2025-08-10 22:47:58,654 [torchrl][INFO] Training time: 356.12 seconds\n",
      "2025-08-10 22:47:58,669 [torchrl][INFO] macs: 211.52 MMac  Params: 57.54 k\n",
      "2025-08-10 22:48:01,283 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 22:48:01,408 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 90.99531555175781: 100%|██████████| 80/80 [10:45<00:00,  8.06s/it] \n",
      "2025-08-10 22:58:46,477 [torchrl][INFO] Training time: 412.98 seconds\n",
      "2025-08-10 22:58:46,493 [torchrl][INFO] macs: 261.05 MMac  Params: 57.54 k\n",
      "2025-08-10 22:58:49,845 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 22:58:50,064 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 53.547157287597656: 100%|██████████| 80/80 [12:09<00:00,  9.12s/it] \n",
      "2025-08-10 23:10:59,858 [torchrl][INFO] Training time: 448.25 seconds\n",
      "2025-08-10 23:10:59,875 [torchrl][INFO] macs: 310.59 MMac  Params: 57.54 k\n",
      "2025-08-10 23:11:04,005 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 23:11:04,176 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 15.200645446777344: 100%|██████████| 80/80 [13:51<00:00, 10.40s/it]  \n",
      "2025-08-10 23:24:55,848 [torchrl][INFO] Training time: 482.06 seconds\n",
      "2025-08-10 23:24:55,871 [torchrl][INFO] macs: 360.13 MMac  Params: 57.54 k\n",
      "2025-08-10 23:25:01,046 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-10 23:25:01,242 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -7.2133660316467285: 100%|██████████| 80/80 [15:28<00:00, 11.60s/it]  \n",
      "2025-08-10 23:40:29,387 [torchrl][INFO] Training time: 518.92 seconds\n",
      "2025-08-10 23:40:29,421 [torchrl][INFO] macs: 409.67 MMac  Params: 57.54 k\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
