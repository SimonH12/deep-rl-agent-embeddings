{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T21:49:57.376069Z",
     "start_time": "2025-08-20T21:49:54.703478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "import torch\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "dir0 = os.path.dirname(dir1)\n",
    "\n",
    "\n",
    "if dir1 not in sys.path: sys.path.append(dir0)\n",
    "\n",
    "from src.config import PPOConfig, EmbeddingStrategy\n",
    "from src.experiments import ExperimentSuite\n",
    "from src.utils import ExperimentUtils\n",
    "\n",
    "\n",
    "def plot_rewards_of_strategy_in_env(list_of_strategies, file_name):\n",
    "    url = \"saved_experiments\" + \"/\" + file_name\n",
    "    base_config_balance_5_agents = PPOConfig(\n",
    "        scenario_name='navigation', use_strategy_defaults=True, n_agents=5, max_steps=100, n_iters=100, decentralized_execution=False\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"strategy\": list_of_strategies\n",
    "    }\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    suite = ExperimentSuite(base_config=base_config_balance_5_agents, param_grid=param_grid, name=\"test_all\", device=my_device)\n",
    "    suite.run_all_confidence(k=10)\n",
    "\n",
    "    suite_utils = ExperimentUtils(path=url, experiment_suite=suite)\n",
    "    suite_utils.save_df_to_file()\n",
    "    suite_utils.plot_experiment_suite_df()\n",
    "    print(suite_utils.create_table_with_confidence())"
   ],
   "id": "27bd201d3250f71b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T21:49:57.424079Z",
     "start_time": "2025-08-20T21:49:57.421515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# strategies = [\n",
    "#     EmbeddingStrategy.CONCAT,\n",
    "#     EmbeddingStrategy.MLP,\n",
    "#     EmbeddingStrategy.MLP_LOCAL,\n",
    "#     EmbeddingStrategy.MLP_GLOBAL\n",
    "# ]\n",
    "#\n",
    "# plot_rewards_of_strategy_in_env(strategies, file_name='5_navigation_mlps_ctce.csv')"
   ],
   "id": "69dc401ecd141926",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T21:49:57.431924Z",
     "start_time": "2025-08-20T21:49:57.430173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# strategies = [\n",
    "#     EmbeddingStrategy.GRAPH_SAGE,\n",
    "#     EmbeddingStrategy.GRAPH_GAT,\n",
    "#     EmbeddingStrategy.GRAPH_GAT_v2\n",
    "# ]\n",
    "#\n",
    "# plot_rewards_of_strategy_in_env(strategies, file_name='5_navigation_gnn_ctce.csv')"
   ],
   "id": "8173f5191357b303",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T21:49:57.439333Z",
     "start_time": "2025-08-20T21:49:57.437171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# strategies = [\n",
    "#     EmbeddingStrategy.SET_TRANSFORMER_INV,\n",
    "#     EmbeddingStrategy.ISAB_TRANSFORMER,\n",
    "#     EmbeddingStrategy.SAB_TRANSFORMER\n",
    "# ]\n",
    "#\n",
    "# plot_rewards_of_strategy_in_env(strategies, file_name='5_navigation_set_ctce.csv')"
   ],
   "id": "4372e4d6be7812e0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T21:49:57.447030Z",
     "start_time": "2025-08-20T21:49:57.444695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_rewards_of_strategy_in_env(list_of_strategies, file_name):\n",
    "    url = \"saved_experiments\" + \"/\" + file_name\n",
    "    base_config_balance_4_agents = PPOConfig(\n",
    "        scenario_name='multi_give_way_com', use_strategy_defaults=True, n_agents=4, max_steps=200, n_iters=100, decentralized_execution=False\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"strategy\": list_of_strategies\n",
    "    }\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    suite = ExperimentSuite(base_config=base_config_balance_4_agents, param_grid=param_grid, name=\"test_all\", device=my_device)\n",
    "    suite.run_all_confidence(k=10, profile_once=True)\n",
    "    suite_utils = ExperimentUtils(path=url, experiment_suite=suite)\n",
    "    suite_utils.save_df_to_file()\n",
    "    # suite_utils.plot_experiment_suite_df()\n",
    "    # suite.rollout_all()\n",
    "    print(suite_utils.create_table_with_confidence())"
   ],
   "id": "5c7f4e512d433d8e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T21:49:57.454895Z",
     "start_time": "2025-08-20T21:49:57.452624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# strategies = [\n",
    "#     EmbeddingStrategy.CONCAT,\n",
    "#     EmbeddingStrategy.MLP,\n",
    "#     EmbeddingStrategy.MLP_LOCAL,\n",
    "#     EmbeddingStrategy.MLP_GLOBAL,\n",
    "# ]\n",
    "#\n",
    "# plot_rewards_of_strategy_in_env(strategies, file_name='5_give_way_mlp_ctce.csv')"
   ],
   "id": "c12ca2c735041e42",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T01:56:51.706743Z",
     "start_time": "2025-08-20T21:49:57.461216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strategies = [\n",
    "    EmbeddingStrategy.GRAPH_SAGE,\n",
    "    EmbeddingStrategy.GRAPH_GAT,\n",
    "    EmbeddingStrategy.GRAPH_GAT_v2\n",
    "]\n",
    "\n",
    "plot_rewards_of_strategy_in_env(strategies, file_name='5_give_way_graph_ctce.csv')"
   ],
   "id": "84344ef0f5490fd3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 23:49:57,522 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-20 23:49:57,761 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0:   0%|          | 0/100 [00:00<?, ?it/s]/opt/miniconda3/envs/ma_rl/lib/python3.9/site-packages/torch_geometric/utils/_scatter.py:79: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::scatter_add_. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/BatchedFallback.cpp:84.)\n",
      "  count.scatter_add_(0, index, src.new_ones(src.size(dim)))\n",
      "/opt/miniconda3/envs/ma_rl/lib/python3.9/site-packages/torch_geometric/utils/_scatter.py:83: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::scatter_add_. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/BatchedFallback.cpp:84.)\n",
      "  out = src.new_zeros(size).scatter_add_(dim, index, src)\n",
      "episode_reward_mean = 8.924165725708008: 100%|██████████| 100/100 [06:26<00:00,  3.86s/it] \n",
      "2025-08-20 23:56:23,862 [torchrl][INFO] Training time: 59.06 seconds\n",
      "2025-08-20 23:56:23,865 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-20 23:56:27,730 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-20 23:56:27,810 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 8.640707969665527: 100%|██████████| 100/100 [07:13<00:00,  4.34s/it]   \n",
      "2025-08-21 00:03:41,534 [torchrl][INFO] Training time: 64.26 seconds\n",
      "2025-08-21 00:03:41,538 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:03:45,408 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:03:45,487 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 12.055683135986328: 100%|██████████| 100/100 [07:20<00:00,  4.40s/it] \n",
      "2025-08-21 00:11:05,959 [torchrl][INFO] Training time: 65.55 seconds\n",
      "2025-08-21 00:11:05,962 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:11:09,880 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:11:09,960 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 12.401071548461914: 100%|██████████| 100/100 [07:22<00:00,  4.42s/it]\n",
      "2025-08-21 00:18:31,997 [torchrl][INFO] Training time: 63.61 seconds\n",
      "2025-08-21 00:18:32,000 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:18:35,982 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:18:36,064 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 2.5481576919555664: 100%|██████████| 100/100 [07:29<00:00,  4.49s/it]  \n",
      "2025-08-21 00:26:05,141 [torchrl][INFO] Training time: 67.06 seconds\n",
      "2025-08-21 00:26:05,144 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:26:09,093 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:26:09,175 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 10.58068561553955: 100%|██████████| 100/100 [07:29<00:00,  4.49s/it] \n",
      "2025-08-21 00:33:38,386 [torchrl][INFO] Training time: 66.39 seconds\n",
      "2025-08-21 00:33:38,388 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:33:42,339 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:33:42,421 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 21.34099578857422: 100%|██████████| 100/100 [07:25<00:00,  4.45s/it]   \n",
      "2025-08-21 00:41:07,854 [torchrl][INFO] Training time: 65.95 seconds\n",
      "2025-08-21 00:41:07,857 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:41:11,819 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:41:11,901 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 17.920312881469727: 100%|██████████| 100/100 [07:34<00:00,  4.54s/it] \n",
      "2025-08-21 00:48:46,034 [torchrl][INFO] Training time: 66.16 seconds\n",
      "2025-08-21 00:48:46,037 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:48:50,124 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:48:50,207 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 12.705620765686035: 100%|██████████| 100/100 [07:29<00:00,  4.50s/it]\n",
      "2025-08-21 00:56:19,877 [torchrl][INFO] Training time: 67.10 seconds\n",
      "2025-08-21 00:56:19,880 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 00:56:23,837 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 00:56:23,920 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 12.697836875915527: 100%|██████████| 100/100 [07:31<00:00,  4.51s/it]  \n",
      "2025-08-21 01:03:55,292 [torchrl][INFO] Training time: 66.79 seconds\n",
      "2025-08-21 01:03:55,295 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 01:03:59,409 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 01:03:59,494 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0:   0%|          | 0/10 [00:00<?, ?it/s][W821 01:04:03.771848000 CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "episode_reward_mean = 1.5899081230163574: 100%|██████████| 10/10 [01:07<00:00,  6.72s/it]\n",
      "2025-08-21 01:05:06,670 [torchrl][INFO] Training time: 27.24 seconds\n",
      "2025-08-21 01:05:22,337 [torchrl][INFO] macs: 4.46 MMac  Params: 4.74 k\n",
      "2025-08-21 01:05:25,652 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 01:05:25,758 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0:   0%|          | 0/100 [00:00<?, ?it/s]/opt/miniconda3/envs/ma_rl/lib/python3.9/site-packages/torch_geometric/utils/_scatter.py:102: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::scatter_reduce_.two. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/BatchedFallback.cpp:84.)\n",
      "  return src.new_zeros(size).scatter_reduce_(\n",
      "/opt/miniconda3/envs/ma_rl/lib/python3.9/site-packages/torch_geometric/utils/_scatter.py:75: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::scatter_add_. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/functorch/BatchedFallback.cpp:84.)\n",
      "  return src.new_zeros(size).scatter_add_(dim, index, src)\n",
      "episode_reward_mean = 1.6608413457870483: 100%|██████████| 100/100 [10:06<00:00,  6.07s/it] \n",
      "2025-08-21 01:15:32,717 [torchrl][INFO] Training time: 202.61 seconds\n",
      "2025-08-21 01:15:32,723 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 01:15:36,909 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 01:15:36,993 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -4.532266616821289: 100%|██████████| 100/100 [10:01<00:00,  6.02s/it]  \n",
      "2025-08-21 01:25:38,763 [torchrl][INFO] Training time: 205.12 seconds\n",
      "2025-08-21 01:25:38,769 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 01:25:42,932 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 01:25:43,017 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 10.55703353881836: 100%|██████████| 100/100 [10:03<00:00,  6.04s/it]  \n",
      "2025-08-21 01:35:46,538 [torchrl][INFO] Training time: 205.80 seconds\n",
      "2025-08-21 01:35:46,544 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 01:35:50,732 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 01:35:50,814 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 2.200284242630005: 100%|██████████| 100/100 [10:04<00:00,  6.04s/it]   \n",
      "2025-08-21 01:45:55,279 [torchrl][INFO] Training time: 207.08 seconds\n",
      "2025-08-21 01:45:55,286 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 01:45:59,458 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 01:45:59,540 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0.24049265682697296: 100%|██████████| 100/100 [10:05<00:00,  6.06s/it]\n",
      "2025-08-21 01:56:05,415 [torchrl][INFO] Training time: 206.63 seconds\n",
      "2025-08-21 01:56:05,421 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 01:56:09,598 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 01:56:09,682 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 12.339669227600098: 100%|██████████| 100/100 [10:01<00:00,  6.01s/it]\n",
      "2025-08-21 02:06:11,093 [torchrl][INFO] Training time: 206.06 seconds\n",
      "2025-08-21 02:06:11,100 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 02:06:15,272 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 02:06:15,356 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -5.064257621765137: 100%|██████████| 100/100 [10:07<00:00,  6.07s/it]\n",
      "2025-08-21 02:16:22,563 [torchrl][INFO] Training time: 206.61 seconds\n",
      "2025-08-21 02:16:22,570 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 02:16:26,742 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 02:16:26,825 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 7.072633743286133: 100%|██████████| 100/100 [10:05<00:00,  6.05s/it]  \n",
      "2025-08-21 02:26:32,025 [torchrl][INFO] Training time: 206.86 seconds\n",
      "2025-08-21 02:26:32,031 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 02:26:36,208 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 02:26:36,292 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -5.209187984466553: 100%|██████████| 100/100 [10:06<00:00,  6.06s/it]\n",
      "2025-08-21 02:36:42,677 [torchrl][INFO] Training time: 207.06 seconds\n",
      "2025-08-21 02:36:42,682 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 02:36:46,845 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 02:36:46,928 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -5.046946048736572: 100%|██████████| 100/100 [10:04<00:00,  6.05s/it]  \n",
      "2025-08-21 02:46:51,508 [torchrl][INFO] Training time: 206.79 seconds\n",
      "2025-08-21 02:46:51,514 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 02:46:55,660 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 02:46:55,743 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -2.899458885192871: 100%|██████████| 10/10 [01:21<00:00,  8.17s/it]\n",
      "2025-08-21 02:48:17,475 [torchrl][INFO] Training time: 41.43 seconds\n",
      "2025-08-21 02:48:31,939 [torchrl][INFO] macs: 28.67 MMac  Params: 30.34 k\n",
      "2025-08-21 02:48:35,284 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 02:48:35,389 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 12.92673110961914: 100%|██████████| 100/100 [06:37<00:00,  3.98s/it]  \n",
      "2025-08-21 02:55:13,251 [torchrl][INFO] Training time: 103.57 seconds\n",
      "2025-08-21 02:55:13,254 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 02:55:16,344 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 02:55:16,408 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 6.840194225311279: 100%|██████████| 100/100 [06:36<00:00,  3.96s/it] \n",
      "2025-08-21 03:01:52,507 [torchrl][INFO] Training time: 104.66 seconds\n",
      "2025-08-21 03:01:52,512 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:01:55,545 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:01:55,609 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 6.827095031738281: 100%|██████████| 100/100 [06:39<00:00,  4.00s/it]  \n",
      "2025-08-21 03:08:35,435 [torchrl][INFO] Training time: 108.60 seconds\n",
      "2025-08-21 03:08:35,439 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:08:38,476 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:08:38,541 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 16.074819564819336: 100%|██████████| 100/100 [06:40<00:00,  4.01s/it] \n",
      "2025-08-21 03:15:19,215 [torchrl][INFO] Training time: 108.39 seconds\n",
      "2025-08-21 03:15:19,220 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:15:22,289 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:15:22,354 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 0.7110940217971802: 100%|██████████| 100/100 [06:36<00:00,  3.96s/it] \n",
      "2025-08-21 03:21:58,456 [torchrl][INFO] Training time: 106.39 seconds\n",
      "2025-08-21 03:21:58,460 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:22:01,530 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:22:01,594 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -0.054564595222473145: 100%|██████████| 100/100 [06:39<00:00,  4.00s/it]\n",
      "2025-08-21 03:28:41,346 [torchrl][INFO] Training time: 107.98 seconds\n",
      "2025-08-21 03:28:41,351 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:28:44,409 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:28:44,474 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 6.2092084884643555: 100%|██████████| 100/100 [06:37<00:00,  3.97s/it]  \n",
      "2025-08-21 03:35:21,850 [torchrl][INFO] Training time: 106.88 seconds\n",
      "2025-08-21 03:35:21,854 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:35:24,925 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:35:24,990 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 5.262509346008301: 100%|██████████| 100/100 [06:38<00:00,  3.99s/it]  \n",
      "2025-08-21 03:42:03,687 [torchrl][INFO] Training time: 107.93 seconds\n",
      "2025-08-21 03:42:03,691 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:42:06,705 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:42:06,769 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 15.252700805664062: 100%|██████████| 100/100 [06:37<00:00,  3.98s/it]  \n",
      "2025-08-21 03:48:44,680 [torchrl][INFO] Training time: 107.20 seconds\n",
      "2025-08-21 03:48:44,684 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:48:47,778 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:48:47,843 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 10.674126625061035: 100%|██████████| 100/100 [06:37<00:00,  3.98s/it] \n",
      "2025-08-21 03:55:25,600 [torchrl][INFO] Training time: 106.65 seconds\n",
      "2025-08-21 03:55:25,604 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n",
      "2025-08-21 03:55:28,663 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:55:28,728 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -2.523939371109009: 100%|██████████| 10/10 [01:02<00:00,  6.26s/it] \n",
      "2025-08-21 03:56:31,358 [torchrl][INFO] Training time: 33.68 seconds\n",
      "2025-08-21 03:56:48,680 [torchrl][INFO] macs: 9.06 MMac  Params: 10.22 k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Experiment  training_time training_memory_usage       inference_time  \\\n",
      "0    graph_sage   65.19 ± 1.42    1645.90 ± 0.00e+00  6.43e-04 ± 2.33e-05   \n",
      "1     graph_gat  206.06 ± 0.79   10930.31 ± 0.00e+00  9.87e-04 ± 3.17e-05   \n",
      "2  graph_gat_v2  106.82 ± 0.94    5540.03 ± 0.00e+00  6.76e-04 ± 2.99e-05   \n",
      "\n",
      "   mean_rewards         loss             flops        parameters  \n",
      "0  11.98 ± 2.97  0.51 ± 0.21   8.92 ± 0.00e+00   9.48 ± 0.00e+00  \n",
      "1   1.42 ± 3.86  1.02 ± 0.15  57.34 ± 4.34e-15  60.68 ± 4.34e-15  \n",
      "2   8.07 ± 3.24  0.61 ± 0.13  18.12 ± 0.00e+00  20.44 ± 0.00e+00  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T06:54:42.967751Z",
     "start_time": "2025-08-21T01:56:51.759472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strategies = [\n",
    "    EmbeddingStrategy.SET_TRANSFORMER_INV,\n",
    "    EmbeddingStrategy.ISAB_TRANSFORMER,\n",
    "    EmbeddingStrategy.SAB_TRANSFORMER\n",
    "]\n",
    "\n",
    "plot_rewards_of_strategy_in_env(strategies, file_name='5_give_way_sett_ctce.csv')"
   ],
   "id": "b49b7eed24d0adc2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 03:56:51,844 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 03:56:51,921 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 352.7160949707031: 100%|██████████| 100/100 [09:50<00:00,  5.91s/it] \n",
      "2025-08-21 04:06:42,588 [torchrl][INFO] Training time: 190.74 seconds\n",
      "2025-08-21 04:06:42,595 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 04:06:46,793 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 04:06:46,876 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 26.34610366821289: 100%|██████████| 100/100 [09:53<00:00,  5.94s/it] \n",
      "2025-08-21 04:16:40,482 [torchrl][INFO] Training time: 199.46 seconds\n",
      "2025-08-21 04:16:40,487 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 04:16:44,665 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 04:16:44,751 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 32.50516891479492: 100%|██████████| 100/100 [09:52<00:00,  5.93s/it] \n",
      "2025-08-21 04:26:37,602 [torchrl][INFO] Training time: 198.45 seconds\n",
      "2025-08-21 04:26:37,609 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 04:26:41,778 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 04:26:41,862 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 26.689807891845703: 100%|██████████| 100/100 [10:40<00:00,  6.40s/it]\n",
      "2025-08-21 04:37:22,204 [torchrl][INFO] Training time: 213.93 seconds\n",
      "2025-08-21 04:37:22,211 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 04:37:26,649 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 04:37:26,738 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 17.23857307434082: 100%|██████████| 100/100 [10:24<00:00,  6.25s/it]   \n",
      "2025-08-21 04:47:51,341 [torchrl][INFO] Training time: 208.59 seconds\n",
      "2025-08-21 04:47:51,349 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 04:47:55,775 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 04:47:55,864 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 22.406675338745117: 100%|██████████| 100/100 [10:06<00:00,  6.06s/it] \n",
      "2025-08-21 04:58:01,890 [torchrl][INFO] Training time: 202.43 seconds\n",
      "2025-08-21 04:58:01,897 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 04:58:06,131 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 04:58:06,216 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 53.51910400390625: 100%|██████████| 100/100 [09:59<00:00,  5.99s/it]  \n",
      "2025-08-21 05:08:05,285 [torchrl][INFO] Training time: 199.59 seconds\n",
      "2025-08-21 05:08:05,292 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 05:08:09,517 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 05:08:09,602 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 31.229177474975586: 100%|██████████| 100/100 [09:53<00:00,  5.94s/it]  \n",
      "2025-08-21 05:18:03,263 [torchrl][INFO] Training time: 197.25 seconds\n",
      "2025-08-21 05:18:03,269 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 05:18:07,458 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 05:18:07,543 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -21.331525802612305: 100%|██████████| 100/100 [09:57<00:00,  5.98s/it]\n",
      "2025-08-21 05:28:05,367 [torchrl][INFO] Training time: 201.53 seconds\n",
      "2025-08-21 05:28:05,375 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 05:28:09,592 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 05:28:09,676 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 39.18246078491211: 100%|██████████| 100/100 [09:52<00:00,  5.93s/it] \n",
      "2025-08-21 05:38:02,545 [torchrl][INFO] Training time: 197.79 seconds\n",
      "2025-08-21 05:38:02,552 [torchrl][INFO] macs: 39.09 MMac  Params: 34.61 k\n",
      "2025-08-21 05:38:06,722 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 05:38:06,804 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 32.79445266723633: 100%|██████████| 100/100 [09:20<00:00,  5.60s/it] \n",
      "2025-08-21 05:47:26,905 [torchrl][INFO] Training time: 171.12 seconds\n",
      "2025-08-21 05:47:26,912 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 05:47:31,016 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 05:47:31,100 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 33.3298225402832: 100%|██████████| 100/100 [09:19<00:00,  5.59s/it]  \n",
      "2025-08-21 05:56:50,266 [torchrl][INFO] Training time: 168.09 seconds\n",
      "2025-08-21 05:56:50,273 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 05:56:54,380 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 05:56:54,464 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = -61.46302795410156: 100%|██████████| 100/100 [09:20<00:00,  5.60s/it]\n",
      "2025-08-21 06:06:14,605 [torchrl][INFO] Training time: 170.81 seconds\n",
      "2025-08-21 06:06:14,614 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 06:06:18,755 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 06:06:18,840 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 26.925945281982422: 100%|██████████| 100/100 [09:18<00:00,  5.58s/it]  \n",
      "2025-08-21 06:15:37,313 [torchrl][INFO] Training time: 168.22 seconds\n",
      "2025-08-21 06:15:37,320 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 06:15:41,513 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 06:15:41,598 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 32.42880630493164: 100%|██████████| 100/100 [09:20<00:00,  5.60s/it] \n",
      "2025-08-21 06:25:02,021 [torchrl][INFO] Training time: 168.71 seconds\n",
      "2025-08-21 06:25:02,030 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 06:25:06,167 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 06:25:06,252 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 29.50992774963379: 100%|██████████| 100/100 [09:15<00:00,  5.56s/it] \n",
      "2025-08-21 06:34:21,796 [torchrl][INFO] Training time: 166.58 seconds\n",
      "2025-08-21 06:34:21,803 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 06:34:25,892 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 06:34:25,977 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 31.13016128540039: 100%|██████████| 100/100 [09:12<00:00,  5.52s/it]  \n",
      "2025-08-21 06:43:38,116 [torchrl][INFO] Training time: 163.61 seconds\n",
      "2025-08-21 06:43:38,126 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 06:43:42,209 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 06:43:42,293 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 32.70660400390625: 100%|██████████| 100/100 [09:13<00:00,  5.53s/it]  \n",
      "2025-08-21 06:52:55,488 [torchrl][INFO] Training time: 165.91 seconds\n",
      "2025-08-21 06:52:55,496 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 06:52:59,579 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 06:52:59,662 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 32.915931701660156: 100%|██████████| 100/100 [09:12<00:00,  5.52s/it]\n",
      "2025-08-21 07:02:12,053 [torchrl][INFO] Training time: 164.15 seconds\n",
      "2025-08-21 07:02:12,058 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 07:02:16,200 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 07:02:16,283 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 29.707691192626953: 100%|██████████| 100/100 [09:12<00:00,  5.53s/it]\n",
      "2025-08-21 07:11:29,189 [torchrl][INFO] Training time: 166.15 seconds\n",
      "2025-08-21 07:11:29,197 [torchrl][INFO] macs: 52.07 MMac  Params: 56.96 k\n",
      "2025-08-21 07:11:33,244 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 07:11:33,325 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 21.25800132751465: 100%|██████████| 100/100 [10:18<00:00,  6.19s/it]  \n",
      "2025-08-21 07:21:51,855 [torchrl][INFO] Training time: 233.85 seconds\n",
      "2025-08-21 07:21:51,861 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 07:21:55,898 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 07:21:55,981 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 30.496906280517578: 100%|██████████| 100/100 [10:18<00:00,  6.19s/it] \n",
      "2025-08-21 07:32:14,730 [torchrl][INFO] Training time: 232.61 seconds\n",
      "2025-08-21 07:32:14,736 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 07:32:18,763 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 07:32:18,845 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 33.101924896240234: 100%|██████████| 100/100 [10:18<00:00,  6.19s/it]\n",
      "2025-08-21 07:42:37,586 [torchrl][INFO] Training time: 234.14 seconds\n",
      "2025-08-21 07:42:37,591 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 07:42:41,669 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 07:42:41,750 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 33.69328308105469: 100%|██████████| 100/100 [10:07<00:00,  6.08s/it] \n",
      "2025-08-21 07:52:49,358 [torchrl][INFO] Training time: 228.23 seconds\n",
      "2025-08-21 07:52:49,366 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 07:52:53,356 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 07:52:53,437 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 18.221797943115234: 100%|██████████| 100/100 [10:12<00:00,  6.12s/it]\n",
      "2025-08-21 08:03:05,595 [torchrl][INFO] Training time: 230.19 seconds\n",
      "2025-08-21 08:03:05,600 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 08:03:09,573 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 08:03:09,653 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 20.161632537841797: 100%|██████████| 100/100 [10:14<00:00,  6.14s/it] \n",
      "2025-08-21 08:13:23,853 [torchrl][INFO] Training time: 230.93 seconds\n",
      "2025-08-21 08:13:23,858 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 08:13:27,833 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 08:13:27,914 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 33.14589309692383: 100%|██████████| 100/100 [10:11<00:00,  6.11s/it] \n",
      "2025-08-21 08:23:39,346 [torchrl][INFO] Training time: 230.91 seconds\n",
      "2025-08-21 08:23:39,353 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 08:23:43,364 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 08:23:43,446 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 10.139031410217285: 100%|██████████| 100/100 [10:15<00:00,  6.16s/it]\n",
      "2025-08-21 08:33:59,426 [torchrl][INFO] Training time: 232.01 seconds\n",
      "2025-08-21 08:33:59,432 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 08:34:03,462 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 08:34:03,543 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 32.46269226074219: 100%|██████████| 100/100 [10:15<00:00,  6.16s/it] \n",
      "2025-08-21 08:44:19,364 [torchrl][INFO] Training time: 232.75 seconds\n",
      "2025-08-21 08:44:19,370 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n",
      "2025-08-21 08:44:23,383 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-08-21 08:44:23,463 [torchrl][INFO] check_env_specs succeeded!\n",
      "episode_reward_mean = 33.51213455200195: 100%|██████████| 100/100 [10:15<00:00,  6.16s/it]  \n",
      "2025-08-21 08:54:38,973 [torchrl][INFO] Training time: 231.74 seconds\n",
      "2025-08-21 08:54:38,979 [torchrl][INFO] macs: 39.53 MMac  Params: 23.55 k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Experiment  training_time training_memory_usage  \\\n",
      "0  set_transformer_inv  200.98 ± 3.71   0.00e+00 ± 0.00e+00   \n",
      "1     isab_transformer  167.34 ± 1.47   0.00e+00 ± 0.00e+00   \n",
      "2      sab_transformer  231.74 ± 1.02   0.00e+00 ± 0.00e+00   \n",
      "\n",
      "        inference_time   mean_rewards          loss              flops  \\\n",
      "0  1.10e-03 ± 1.38e-05  58.05 ± 61.04  -1.10 ± 0.74   78.18 ± 8.68e-15   \n",
      "1  8.53e-04 ± 1.39e-05  22.00 ± 17.04  -1.69 ± 0.42  104.14 ± 8.68e-15   \n",
      "2  7.44e-04 ± 9.64e-06   26.62 ± 4.90  -0.96 ± 1.67   79.06 ± 8.68e-15   \n",
      "\n",
      "          parameters  \n",
      "0   69.22 ± 0.00e+00  \n",
      "1  113.92 ± 0.00e+00  \n",
      "2   47.10 ± 4.34e-15  \n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
