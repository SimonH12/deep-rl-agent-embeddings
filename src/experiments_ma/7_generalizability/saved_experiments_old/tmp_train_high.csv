name,config,kpi
transformer_global,"PPOConfig: {'scenario_name': 'balance', 'strategy': <EmbeddingStrategy.TRANSFORMER_GLOBAL: 'transformer_global'>, 'n_agents': 20, 'decentralized_execution': True, 'frames_per_batch': 6000, 'n_iters': 10, 'num_epochs': 8, 'minibatch_size': 400, 'lr': 0.0003, 'max_grad_norm': 1.0, 'clip_epsilon': 0.2, 'gamma': 0.99, 'lmbda': 0.9, 'entropy_eps': 0.0001, 'max_steps': 200, 'embedding_depth': 1, 'embedding_num_cells': None, 'hidden_layer_width': 48, 'use_encoder_mlp': True, 'attention_heads': 1, 'model_dim': 32, 'max_agents': 20, 'inducing_points': 4, 'mlp_core_depth': 2, 'mlp_core_num_cells': 64, 'pooling_method': 'mean', 'embedding_mlp_critic': None, 'embedding_mlp_actor': None, 'core_mlp_actor': None, 'core_mlp_critic': None, 'profile': False, 'use_strategy_defaults': True}","{'inference_time': 0.0011685817085917872, 'inference_memory_usage': 0.0, 'loss': [2.5445862929026286, 2.571435765425364, 2.5294630428155265, 2.5525622725486756, 2.6146520634492236, 2.5526578625043235, 2.3058462838331857, 2.1232501616080603, 1.7377599348624548, 1.8842161526282628], 'mean_rewards': [1.5037652254104614, 2.3476650714874268, 3.8210127353668213, 5.283468246459961, 4.7439165115356445, 9.670084953308105, 13.397494316101074, 19.023147583007812, 29.132076263427734, 28.322301864624023], 'training_memory_usage': 0.0, 'training_time': 418.8915317058563, 'flops': 2340.0, 'parameters': 289.82}"
